---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: page
title: Team members  # Page title
---

<div align="center">
  <img src="/assets/images/MFO_zugeschnitten.jpg" width="300">
</div>

<div align="center">
<h1>Ekkehard Schnoor</h1>
</div>

Welcome to my academic website! I'm a PostDoc in the <a href="https://ml4bigdata.github.io/" target="_blank" rel="noopener">Machine Learning Research Group</a> at Aalto University, led by 
<a href="https://ml4bigdata.github.io/alex_jung/" target="_blank" rel="noopener">Alex Jung</a>, with a broad interest in the foundations of machine learning. 
Feel free to reach out if you are interested in <a href="https://scholar.google.de/citations?user=s1qhNzIAAAAJ&hl=de" target="_blank" rel="noopener">my work</a>! 
 
## üìñ Bio
<p>
Before joining Aalto University, I was a member of the <a href="https://www.hhi.fraunhofer.de/en/departments/ai/research-groups/explainable-artificial-intelligence/team.html" target="_blank" rel="noopener">Explainable AI group at Fraunhofer HHI</a>.
Prior to this, I obtained my PhD in mathematics from RWTH Aachen University under supervision of <a href="https://scholar.google.com/citations?user=KA2BM_UAAAAJ&hl=en" target="_blank" rel="noopener">Holger Rauhut</a> for my <a href="https://publications.rwth-aachen.de/record/1012246" target="_blank" rel="noopener">dissertation</a> in statistical learning theory, at the intersection of compressive sensing and deep learning.
The overall goal of my research is to establish rigorous performance guarantees for high-dimensional machine learning, typically drawing on tools from high-dimensional probability and
leveraging on the concentration of measure phenomenon. 
I'm also part of the team behind the <a href="https://aaltodictionaryofml.github.io/" target="_blank" rel="noopener">Aalto Dictionary of Machine Learning</a>. <br><br>

<a href="https://mathscinet.ams.org/mathscinet/freetools/collab-dist?source=1550644&target=189017" target="_blank" rel="noopener">My Erd√∂s number is 4</a>, via Holger Rauhut, J√ºrgen Prestin, and Charles Kam-tai Chui.
</p>

## üî¨ Research

I'm interested in a complementary view on machine learning, combining the perspectives of generalization and explainability, in a variety of interesting scenarios.
<ul>
  <li><strong>Generalization:</strong> Including <em>both</em> non-asymptotic (e.g., using the Rademacher complexity) and asymptotic (based on random matrix theory) approaches.</li>
  <li><strong>Explainability:</strong> In particular, Concept Activation Vectors (CAVs), and Sparse Autoencoders (SAEs) for Large Language Models (LLMs).</li>
  <li><strong>Settings:</strong> Spanning a spectrum from basic linear models to deep neural networks, including networked models as in federated learning, and reinforcement learning.</li>
  <li><strong>Techniques:</strong> Employing powerful tools from high-dimensional probability, such as chaining, random matrix theory (RMT), and (probabilistic) fixed-point methods.</li>
</ul>

## üìö Selected Publications

For a complete list of publications, see my <a href="https://scholar.google.de/citations?user=s1qhNzIAAAAJ&hl=de" target="_blank" rel="noopener">Google Scholar profile</a>.

## üè¢ Contact
üìç Aalto University, Finland  
üìß [ekkehard.schnoor@aalto.fi](mailto:ekkehard.schnoor@aalto.fi)  
üîó [Google Scholar](https://scholar.google.de/citations?user=s1qhNzIAAAAJ&hl=de&oi=ao) |  [GitHub](https://github.com/ekki25) | [LinkedIn](https://www.linkedin.com/in/ekkehard-schnoor/)


[Go Home](/)

